---
layout: post
title:  "🐳 Docker study 5th"
series: "docker"  # Docker 시리즈에 대한 시리즈 지정
subtitle: "The New Standard for Big Data Management: ADLS2 and Docker Integration Guide"
date:   2024-10-25
author: Arielle
categories: [Code & Road] #Story Garage
tags:   Docker BigData ADLS2 CloudStorage Azure DataLake
#cover:  "/assets/instacode.png"
---



---

<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Docker Study</title>
    <style>
        h2, h4 {
            color: SteelBlue;
        }
    </style>
</head>
<body>
</body>
</html>

<p>
<em>
지난주까지 우리는 로컬과 가상머신의 연결을 통해 Dockerfile, Image, Container를 관리하는 방법을 배웠다. 독특하게 Microsoft Azure은 가상연결 방식 외에도 ADLS2(Azure Data Lake Storage Gen2)라는 일명 데이터 저장소 플랫폼을 운영하고 있다.
</em>
</p>

<p>
<em>
사실 ADLS2? 공부하기 전까지 들어본 적도 없는 친구였다. 혹시 오늘의 포스팅을 들어가기 앞서 <em>“ADLS2? 꼭 알아야 되나?</em>😬” 라고 떠올릴 수도 있다. ‘Data Lake’라는 개념이 등장하면서 빅데이터 분석, 머신러닝, IoT, 엔터프라이즈 데이터 관리 등 실제 이 ADLS를 채택하고 있는 기업들이 많아진 것을 생각해봤을 때, Docker같은 가상화 기술을 공부하는 입장에서 이는 분명 시너지가 될 수 있다고 생각한다!
</em>
</p>

<p>
<em>
오늘은 이 ADLS2가 도대체 어떤 역할을 하고, 왜 우리가 알아두면 좋을지, 그리고 Docker와의 연계가 어떻게 이루어지는지에 대해 이야기 해보도록 한다!🚀
</em>
</p>

---
<h2>1. Connecting Azure Storage Account with Blobfuse</h2>

**Azure Storage Account**는 Microsoft Azure에서 제공하는 **클라우드 기반 스토리지 서비스**로 데이터를 안전하고 확장 가능하게 저장할 수 있는 공간을 제공하고 있다. 이 저장소는 다양한 종류의 데이터를 처리할 수 있어 기업이나 개발자들이 필요에 따라 원하는 데이터를 손쉽게 저장하고 관리할 수 있도록 돕는 플랫폼 정도로 이해하면 된다. 

나는 그 중 특히 ‘Blob Storage’를 이용해 데이터를 저장해 두었는데 생각보다 되게 좋았던 점은 이미지, 스크립트파일(python, c, c++ etc.), 텍스트파일, 엑셀파일 등 진짜 어떤 데이터든 모두 올려두고 내가 가상환경에서 작업을 하던, 로컬에서 작업을 하던 원하는 데이터를 가져올 수 있다는 것이다. *(앞으로는 가져온다는 개념을 마운트(mount)라고 정리할게요!)* 그리고 참고로 아직은 무엇인지 잘 감이 안잡히는 이 ‘Blob Storage’에 ‘Data Lake’ 기능을 추가해 만들어진 것이 바로 이번 포스팅의 키워드, ADLS인 것이다!  

그럼 지금부터 단계별로 어떻게 Storage Account를 생성하고 가상환경과 연동할 수 있는지 이어서 이야기해보록 하겠다!

<h4>1.1 Creating a Storage Account</h4>

가장 먼저 해야 할 일은 Azure에서 Storage Account를 만드는 것이다. 아래 사진을 보면 500TB까지 데이터를 저장할 수 있다고 하니 웬만한 빅데이터 프로젝트를 사용하는데는 큰 무리가 없을 것 같다. 

<img src="{{ '/assets/p.23/p23.1.png' | relative_url }}" alt="Descriptive Alt Text" />

Storage Account를 초기 생성할 때 아래 사진처럼 세부적인 조건들을 설정할 수 있다. 나는 ‘kaggleaccountsh’라는 이름으로 생성해 주었다. 

<img src="{{ '/assets/p.23/p23.2.png' | relative_url }}" alt="Descriptive Alt Text" />

하단의 Review + create를 누르면 다음 페이지로 넘어가게 되고 해당 storage 접근 방식도 선택이 가능하고 나는 key 방식으로 선택해주었다. 여기서 한가지 중요한 포인트는 바로 **Enable hierarchical namespace를 활성화** 해주는 것이다. 이 옵션의 활성화 여부는 정확히 어떤 스토리지가 필요한지에 따라 다를 수 있지만, 대부분의 경우 스토리지 생성 과정에서 이 옵션을 선택해 주는 것이 일반적이다! 

그 이유에 대해서 이해하고자 한다면 머릿속에 흩어져있는 여러 개념들을 선정리하고 가야한다. Blob Storage 부터 시작해보도록 한다!

<img src="{{ '/assets/p.23/p23.3.png' | relative_url }}" alt="Descriptive Alt Text" />

---

<h4>🗂️ Blob Storage</h4>

#기본 중의 기본

**Blob Storage**는 비정형 데이터(이미지, 동영상, 로그 파일 등)를 저장하는 Azure의 기본 스토리지 서비스이다가장 큰 특징은 **간단하고 확장 가능**하다는 점인데, 데이터가 많아지더라도 언제든 쉽게 확장할 수 있고 여러 클라우드 서비스와도 잘 연동된다. 단순한 구조와 더불어 확장가능성이 가장 큰 메리트이지만 오히려 이 장점으로 인해 대규모 데이터를 관리할 때는 적합하지 않다. 

쉽게 설명해보면 이렇다. 만약 내가 특정 파일이 필요하다면 바로 해당 파일에 접근할 수 없고 맨 처음부터 하나씩 하나씩 그 파일을 찾으러 나서야 된다는 말이다. 그래서 Hierarchical Namespace 개념이 등장하게 된 것이고. 대규모의 데이터를 다루는 프로젝트라면 확장성의 강점인 Blob Storage에 이 Hierarchical Namespace 옵션을 추가해 사용해주면 된다.


<br>
<h4>🗂️ Hierarchical Namespace</h4>

#깔끔한 데이터 관리의 비결

**Hierarchical Namespace(계층적 네임스페이스)**는 말 그대로 **데이터를 계층적인 폴더 구조로 정리해서 저장**할 수 있는 기능이다. 컴퓨터 파일 시스템처럼 폴더를 만들어 그 안에 여러 파일들을 정리해 두는 것처럼 스토리지 공간 안에서도 폴더*(여기서는 Container라고 부름. 단, 도커의 가상환경 Container와 이름만 똑같고 기능은 완전히 다름!)*를 통해 데이터를 정리할 수 있다. 위에서 대부분의 경우 스토리지 생성 과정에서 해당 옵션을 선택한다고 했는데, 이게 왜 그럴까?

일반적인 **Blob Storage에서는 파일들이 평면적인 구조로 저장**됩니다. 이게 무슨 뜻이냐 하면 파일이 계층적인 폴더 구조로 저장되는 것이 아니라 파일 경로가 그저 하나의 문자열처럼 처리된다는 말이다. 예를 들어 `/dockercourse/python/run.py`라는 경로를 보면  `python`이 폴더처럼 보일 수 있지만, Blob Storage에서는 실제로 폴더가 아니다! **이 경로 전체가 파일 이름의 일부**일 뿐, `python`이라는 디렉토리 자체가 존재하는 것은 아닌 점을 이해해야 한다.

위에서 언그한 것처럼 우리는 Hierarchical Namespace를 사용해 Blob Storge를 ADLS2처럼 폴더 구조로 관리할 수 있다. 아래 사진처럼 Microsoft Azure Storage Explorer을 이용해 시각적으로 폴더의 구조를 확인해 볼 수 있다. `mounteddrive` 폴더가 바로 Hierarchical Namespace를 활용해 만들어진 폴더인 것이다!

<img src="{{ '/assets/p.23/p23.3.1.png' | relative_url }}" alt="Descriptive Alt Text" />


<br>
<h4>🗂️ ADLS2</h4>

#클라우드 스토리지의 게임 체인저 #자율주행 프로젝트

만약 우리가 한 자동차 회사의 자율주행 프로젝트를 진행하게 되었다고 생각해보자. 그 때 발생할 수 있는 가장 큰 고민은 무엇일까? 내가 생각하기에는 **데이터 관리**와 그에 따른 **클라우드의 비용의 효율성,** 이 두 가지일 것 같다. 

자율주행 프로젝트처럼 대규모 데이터를 다루고 비용 관리와 데이터 보안까지 신경써야 되는 분야는 없다고 생각한다. 차량에서 수집되는 대용량의 센서 데이터, 비디오 스트림, 주행 기록 등을 효율적으로 저장하고 관리해야 하기 때문에 이를 확장 가능한 스토리지로 관리할 절대적인 필요가 있기 때문이다. 그런데 **ADLS2 (Azure Data Lake Storage Gen2)**는 이 두 가지 문제의 솔루션을 제공하고 있다.

ADLS2는 마치 자율주행 시스템의 정돈된 도로와 같다. Hierarchical Namespace 기능을 통해 수집된 데이터를 마치 도로 위의 교통 흐름처럼 체계적으로 저장할 수 있기 때문이다. 자율주행에서 다루는 데이터는 비디오 피드, 라이다(LiDAR) 데이터, 센서 값 등 매우 다양한데, ADLS2는 이 데이터를 폴더 기반으로 정리해 마치 도로 구역을 나누듯 데이터를 분류하고 체계적으로 관리할 수 있다. 

기존의 방식에서는 데이터를 한 곳에 평면적으로 쌓아두어 찾는 데 시간이 걸렸다면 ADLS2는 계층적 폴더 구조 덕분에 데이터를 쉽게 검색하고 관리할 수 있어 **폴더를 찾는 시간 절약**을 기대할 수 있다. 

자율주행 프로젝트에서는 어떤 한 팀은 센서 데이터를 처리하고 다른 팀은 비디오 피드를 분석하는 것처럼 여러 팀이 동시에 작업을 진행한다. 하지만 분명한 건 **모든 팀이 모든 데이터에 접근할 필요는 없다! ADLS2는 ‘Granular Access Control’ 기능을 통해 특정 데이터에 대한 접근 권한을 조절**할 수 있다.

센서 데이터를 다루는 팀은 그 데이터에만 접근할 수 있고 비디오 데이터를 처리하는 팀은 해당 영역에만 접근하도록 설정해 **데이터 보안이 강화**되고 팀별로 필요한 정보만을 사용하게 되어 **효율적인 협업**이 가능해질 수 있다. 

자율주행은 실시간으로 데이터를 처리해야 하는 만큼 언제든 데이터가 급증할 수 있어 저장 용량을 미리 예측하기 어려울 때가 많다. 기존 방식에서는 용량을 크게 설정해두고 사용하지 않은 공간에 대해서도 비용을 지불해야 했지만  ADLS2는 **사용한 만큼만 비용을 지불**하면 된다.

초기에는 비디오 데이터와 센서 데이터를 적게 수집하다가 차량 테스트가 진행되면서 데이터가 급격히 증가할 수도 있는데, 이럴 때 즉각적으로 스토리지의 **추가 공간을 확보해 유동적으로 대응**할 수 있다. 필요할 때만 스토리지를 확장해서 사용하면 되니 자율주행 프로젝트와 같은 대규모 데이터 처리 환경에서 **비용 효율성**이 크게 향상 될 수 있다!

---

다시 storage account 생성으로 돌아와 이야기를 이어나가보도록 하겠다. 최종적으로 생성 작업이 끝나면 아래와 같이 Storage accounts에 내가 만든 컨테이너가 생성됨을 확인할 수 있을 것이다. 그리고 다음 작업이 이 컨테이너 안에 위에서 정리한  Hierarchical Namespace 기능을 이용해 폴더들을 만들 수 있다.

나는 mountedrive라는 이름으로 폴더를 생성해 주었고, 실제로 로컬의 텍스트 파일을 해당 폴더에 업로드해주었다.

<img src="{{ '/assets/p.23/p23.4.png' | relative_url }}" alt="Descriptive Alt Text" />

<img src="{{ '/assets/p.23/p23.5.png' | relative_url }}" alt="Descriptive Alt Text" />

<h4>1.2 Connecting a Storage Account to a Virtual Machine</h4>

Blob Storage를 가상머신과 연결하기 위해서는 크게 세 단계가 필요하다. 

1️⃣ 마이크로소프트에서 제공하고 있는 패키지를 설치해 주면 된다. 참고로 나는 Ubuntu 패키지(**코드 참고** 👉[Configure the Microsoft package repository](https://learn.microsoft.com/en-us/azure/storage/blobs/storage-how-to-mount-container-linux?tabs=Ubuntu#mount))로 진행했다. 

그 전에 먼저 `cat /etc/os-release` 로 연동하고자 하는 가상머신의 운영체제를 확인해 주었다. 보면 나의 가상머신은 Ubuntu 22.04 버전으로 나온다. 이후 `sudo wget https://packages.microsoft.com/config/ubuntu/<VERSION_ID 넣기>/packages-microsoft-prod.deb` 로 패키지를 설치해주면 된다!

<img src="{{ '/assets/p.23/p23.6.png' | relative_url }}" alt="Descriptive Alt Text" />

이어서 아래 코드를 각각 실행해주면 기본적인 패키지 설치는 완료된다.

`sudo dpkg -i packages-microsoft-prod.deb` , `sudo apt-get update`

<img src="{{ '/assets/p.23/p23.7.png' | relative_url }}" alt="Descriptive Alt Text" />

2️⃣ 이후 가상머신에 Storage Account에 접근할 수 있는 권한을 부여해 주었다.  `mkdir mycontainer`, `mkdir blobfuse` 로 먼저 폴더를 생성했고 이후 `/blobfuse/` 하위 경로에 `blobfuse.cfg` 파일을 생성해 주었다. 

`blobfuse.cfg` 파일은 Blob Storage에 연결하기 위해 필요한 설정 파일이다. 따라서 이 파일 안에 Storage Account와 Container에 접근할 수 있는 정보들을 담아 권한을 부여할 수 있다! ( **코드참고**  👉 [Authorize access to your storage account](https://learn.microsoft.com/en-us/azure/storage/blobs/storage-how-to-mount-container-linux?tabs=Ubuntu#mount))

<img src="{{ '/assets/p.23/p23.8.png' | relative_url }}" alt="Descriptive Alt Text" />

Storage Account 이름, 키, 컨테이너 이름을 설정해 주면 된다. 마지막 줄은 key 방식으로 인증한다는 뜻이니 수정할 필요가 없다. 두번째 account key같은 경우에는 Azure 에서 Storage accounts > 생성한 storage 로 접근 후 Security +networking > Access keys 카테고리에서 확인 가능하다. 보면 key 1,2가 있는데 첫번째 파랑색 줄로 표시해 놓은 키를 복사해서 nano 편집기에 붙여 넣으면 된다.

<img src="{{ '/assets/p.23/p23.9.jpg' | relative_url }}" alt="Descriptive Alt Text" />

3️⃣ nano 편집기로 파일을 잘 저장 후 `blobfuse` 를 사용하여 Blob Storage를 로컬 파일 시스템에 마운트 해주었다. 해당 명령어는 아래 명령어를 참고하면 된다!

`blobfuse <Blob Storage를 마운트할 로컬 경로> --tmp-path=<blobfuse가 사용할 임시 저장 경로> --config-file=/<위에서 생성한 nano.cfg 파일 경로>` 

앞의 세 단계를 무사히 진행했다면 가상머신에서도 ‘ADSL2 파일 업로드 실습 중 .txt’ 라는 폴더를 확인할 수 있다. 이 파일은 우리가 앞서 Azure Storage Account > mounteddrive 폴더에 업로드 해둔 파일이다! 연동이 최종적으로 잘 되었다! 😆

<img src="{{ '/assets/p.23/p23.10.png' | relative_url }}" alt="Descriptive Alt Text" />

<img src="{{ '/assets/p.23/p23.11.png' | relative_url }}" alt="Descriptive Alt Text" />


<h2>2. Using Azure Storage Explorer </h2>

[Azure Storage Explorer](https://azure.microsoft.com/en-us/products/storage/storage-explorer)를 사용하면 클라우드 스토리지 관리를 GUI를 통해 더 쉽게 컨트롤할 수 있다. 나는 맥북을 사용하기에 macOS arm64로 설치해 주었다. 윈도우, 리눅스도 있으니 본인의 로컬 운영체제에 맞게 설치해 주면 된다. 설치 방법은 쉬우니 천천히 하면 큰 어려움 없이 진행될 것이다. 아래는 설치 후 초기 화면이다! 

<img src="{{ '/assets/p.23/p23.12.png' | relative_url }}" alt="Descriptive Alt Text" />

<1.2 Connecting a Storage Account to  a Virtual Machine> 에서는 Storage Account와 가상머신 간의 연동을 진행했었다. 이번에는 이 Azure Storage Explorer와  Storage Account간의 연동을 해보았다. Explorer 연동 방식은 **1️⃣ KEY 방식, 2️⃣ SAS(Shared Access Signature) 방식, 3️⃣ RBAC(Role Based Access Control) 방식** 총 세가지로 진행했다.(*사실 더 많다!* 👉 [Authorization mechanisms](https://learn.microsoft.com/en-us/azure/storage/blobs/data-lake-storage-access-control-model?wt.mc_id=searchAPI_azureportal_inproduct_rmskilling&sessionId=416f578211824749b3736e7d6ad23833))

‘연동하는데 꼭 세가지나 알아야 되나?’ 라고 생각할 수 있다. 이해한다. 나역시 일단 하나라도 정확히 알자 주의니까 말이다. 그럼에도 불구하고 세가지 방식을 모두 소개하는 이유는 각각의 방식들이 가진 장단점이 명확하기 때문이다. 내가 어떤 환경환경에서 Storage Account를 사용하게 될지 사실 아무도 모른다. 데이터 권한 문제도 있을 수 있고, 보안 문제, 어쩌면 최대한 빨리 이 데이터를 다른 팀에 넘겨야 하는 시간 문제도 있을 수 있다. 그러니 무조건 하나의 방법만 고집하는 것보다는 여러 방식을 알아두고 상황에 맞게 유연하게 대처하는 것이 더 센스있는 개발자가 되는 길이 아닐까?

<h4>2.1 Key</h4>

첫번째는 1️⃣ KEY 방식이다.  말 그대로 Storage 계정의 Access key를 사용하여 연결하는 방식으로 키를 사용하면 해당 스토리지 계정에 대해 전체 권한을 부여 받을 수 있다. 이 방식의 최대 장점은 **빠르고 간단**하다는 것이다. 어느 환경에서든 해당 스토리지의 키만 알고 있다면 누구든 접근할 수 있다. 하지만 이 방식에는 **보안 리스크**가 따른다. Access Key와 스토리지 계정이 일대일로 대응되기 때문에 키가 유출될 경우 계정 전체의 보안이 위험해질 수 있다.

그렇다면 장점보다 단점이 더 커보이는 이 방식을 그럼 대체 왜 사용하는 걸까? 주로 **테스트나 개발 환경**처럼 시간 효율성이 중요한 경우 유용하기 때문이다. 분명 빠르게 연결이 필요한 상황에서는 유리하지만, 생산 환경에서는 권장되지 않는 방식이다. 그러니 보안이 중요한 곳에서는 다른 방식을 선택하면 된다! 

연동 방법도 꽤 간단한 편이다. 아래 사진처럼 원하는 Storage Account를 우클릭(Connect to Azure Storage) 하면 팝업창이 뜨는데 ‘Storage account or service’ 옵션을 선택해주면 된다.

<img src="{{ '/assets/p.23/p23.13.png' | relative_url }}" alt="Descriptive Alt Text" />

연결 방식은 당연히 ‘Connection string(Key or SAS)’를 선택해 주면 된다. 

<img src="{{ '/assets/p.23/p23.14.png' | relative_url }}" alt="Descriptive Alt Text" />

그러면 ‘Connecting String’ 키를 입력하라는 팝업이 뜨게 되는데, 해당 키는 아래 사진을 참고해 붙여 넣어주면 된다! 참고로 Display name은 키를 입력하면 자동 생성되니 사용자가 원하는대로 수정해 주면 된다.

<img src="{{ '/assets/p.23/p23.15.jpg' | relative_url }}" alt="Descriptive Alt Text" />

<img src="{{ '/assets/p.23/p23.16.png' | relative_url }}" alt="Descriptive Alt Text" />

---

👇 **summary(Key)**

- **Description** : Storage Account에 대한 권한 접근.
- <span style="color: rgb(27, 120, 196);">**Pros**: 빠르고 간단하게 설정할 수 있음. 키만 있으면 어느 환경에서든 스토리지에 접근 가능함! </span>
- <span style="color: rgb(255,99,100);">**Cons**: 보안 위험이 큼. Access Key가 전체 Storage 계정과 직접 연결되어 있어 키가 유출되면 계정 전체가 위험해질 수 있음.</span>
- **When to Use?** : 테스트나 개발 환경에서 빠르게 연결이 필요할 때 유용하지만 그외(운영)의 환경에서는 권장되지 않음.

---

<h4>2.2 SAS</h4>

**2️⃣ SAS(Shared Access Signature)**은 토큰을 이용해 Storage Account 전체가 아닌 내부의 폴더 즉 Container 별로 제한된 접근을 허용하는 방식이다. 특정 Container에 대해 읽기, 쓰기 등의 수정 여부를 지정해줄 수 있어 꽤 유용하게 사용된다. 효율성 측면에서도 좋은 것 뿐만 아니라 당연히 Key 방식과 달리 **Container 하나하나를 원하는 대로 제어할 수 있어 보안성 측면에서 훨씬 안전**한 것이 사실이다. 단점은 토큰의 특성 상 기간 만료를 신경 써야 하지만 보안 측면의 장점이 더 커보이는 것 같다. 

 아래는 ‘mounteddrive2’라는 새로운 Container를 만들어 SAS 방식을 실습해 본 사진이다. Settomgs > Shared access tockens 카테고리로 들어가면 토큰의 기간을 지정해 줄 수 있다. 만약 회사 외부 파트너 혹은 임시 테스트 프로그램 상 일부 데이터에 접근해야 할 필요가 있을 때, 그 때 상황에 맞게 일시적으로 권한을 부여해 주는 방식으로 사용된다. (해당 페이지 하단의 ‘Blob SAS URL’로 연결 진행!)

<img src="{{ '/assets/p.23/p23.17.png' | relative_url }}" alt="Descriptive Alt Text" />

Azure Storage Explorer에서는 ‘ADLS Gen2 container or directory’ 옵션을 선택해주면 된다. 

이후에 나오는 ‘Enter Connection Innfo’ 페이지의 경우에는 ‘Blob SAS URL’을 복사해서 그대로 붙여 넣어주었다.

<img src="{{ '/assets/p.23/p23.18.png' | relative_url }}" alt="Descriptive Alt Text" />

<img src="{{ '/assets/p.23/p23.19.png' | relative_url }}" alt="Descriptive Alt Text" />

아래 사진으로 Key 방식과 SAS 방식의 차이점을 쉽게 이해할 수 있다. 컨테이너 별 우측에 괄호로 어떤 방식으로 연결되었는지 표시가 되어있긴 하지만, 폴더 구조 측면에서 보면 SAS의 경우 `Storage Account/Blob Container/mounteddrive2` 로 연동되어 있고 Key의 경우 `Storage Account/kaggleaccountsh/Blob Containers` 경로로 접근 되었음을 확인 할 수 있다.

<img src="{{ '/assets/p.23/p23.20.jpg' | relative_url }}" alt="Descriptive Alt Text" />

추가로 토큰을 이용한 SAS 연결 방식에서 꽤 신기한 점도 배웠다. 바로 웹에서 컨테이너 내 파일을 확인할 수 있는 방식으로 아래 웹 주소를 이용하면 된다!  

✅ https://Storage account.blob.core.windows.net/container/folder/file?Blob SAS token

지금 보면 `mounteddrive2/testdrive/connect with token feat.SAS.txt` 경로로 텍스트 파일이 위치해 있다.

<img src="{{ '/assets/p.23/p23.21.png' | relative_url }}" alt="Descriptive Alt Text" />

<img src="{{ '/assets/p.23/p23.22.png' | relative_url }}" alt="Descriptive Alt Text" />

본인의 Storage, Container 경로에 맞게 주소를 수정해서 실행하면 신기하게도 웹에서 해당 파일을 직접 확인 할 수 있다. *(나는 이 부분이 꽤 신기했다. 그리고 엄청 유용하게 쓰일 수도 있을 거라 생각한다!* 😲 *)*

✅ https://kaggleaccountsh.blob.core.windows.net/mounteddrive2/testdrive/connect with token feat.SAS.txt?Blob SAS token



























































---- 경 계 선 ---
<h4>1.2 Running an R container in the RStudio Server IDE environment</h4>
지금까지 도커를 사용함에 있어 먼저 필요한 이미지를 다운받고 이를 해당 컨테이너, 즉 가상환경의 터미널에서 실행시키는 방법으로 진행했다. 이번에는 IDE 환경(Web)에서 컨테이너를 실행시켜보는 방법을 RStudio Server를 이용해 시도해보았다. 

아래 사진은 실제로 R 컨테이너를 통해 IDE에 접근한 결과인데, 보면 웹에서 성공적으로 실행되고 있음을 확인할 수 있다.

<img src="{{ '/assets/p.14/p14.2.png' | relative_url }}" alt="Descriptive Alt Text" />

이를 위한 방법은 이 명령어 한 줄 이면 가능하다. 조금 길긴 하지만 하나하나 읽어보면 또 완전히 못 할 것도 아닌 듯 싶다.

✅ <strong>Rstudio Web Browser connect code</strong>  <code>docker run -d -p 8787:8787 --gpus all -v "/home/Arielle/rproject:/home/rstudio/rproject" --name rstudio-container gcr.io/kaggle-gpu-images/rstats:v59 /bin/bash -c "rstudio-server start && tail -f /dev/null"</code>

<code>docker run -d</code>는 새로운 컨테이너를 지정된 이미지를 사용해 실행시키는 명령어이다. <code>-d</code> 옵션을 사용하면 "Detached mode"로 컨테이너가 백그라운드에서 실행되는데, 덕분에 터미널이 컨테이너에 묶이지 않고 다른 작업을 계속할 수 있다! 만약 해당 옵션을 사용하지 않으면 컨테이너가 실행되는 동안 터미널이 그 작업에만! 붙잡혀 있어 다른 명령어를 입력할 수가 없는 상황이 되기 때문에 주의가 필요하다!

<code>-p 8787:8787</code> 의 경우 포트 포워딩을 설정하는 옵션으로 컨테이너의 8787 포트(즉, RStudio Server가 실행되는 기본 포트)를 호스트 시스템의 동일한 8787 포트와 연결하는 역할을 한다. 이 설정 덕분에 웹 브라우저에서 ‘http://localhost:8787’을 입력하면 RStudio Server에 접근할 수 있게 되는 것이다. 

그런데 이렇게 간단하게 문장으로 설명하기는 했지만, 사실 나는 포트에 대한 개념이 딱 정리되어 있지는 않은 상태에서 강의를 듣다보니 내가 제대로 이해한 게 맞는지 혼란스러웠다.(아마 내가 아는 포트는 1004, 22번 포트 정도??🤨)그래서 다시는 포트에 대해서 헷갈리지 않겠다는 다짐으로 이에 대해서 잠깐 정리하고 넘어가도록 하고자 한다!

---
<h4>🚪 Port?</h4>

일단 나는 Port가 정확히 모르지만 알게모르게 여기저기 사용하고 있긴 했다. 앞서 [RDP 방식으로 MAC 가상환경을 구축](https://arielle0222.github.io/code%20&%20road/2024/10/05/docker.html)할 때가 대표적이다. 아래 사진은 내가 이해한 Port의 개념을 정리한 그림이다. 

<img src="{{ '/assets/p.14/p14.1.1.png' | relative_url }}" alt="Descriptive Alt Text" />

클라이언트와 서버의 측면에서 이해하고자 한다면 좌측처럼 서버에게 사용하려고 하는 서비스 각각에게 부여된 특정 포트번호를 통해 클라이언트와 연결할 수 있다. 대표적으로  위에서 언급한 RDP 방식은 3389 포트를, SSH는 22번 포트를, 그리고 VNC는 5900번 포트를 이용해 연결한다. 

그렇다면 도커 컨테이너 관점에서 이해해보면 어떨까? 이 관점에서는 기존의 클라이어트가 로컬 호스트(Local Host)로 서버는 컨테이너(Container) 개념으로 바꾸어 생각해볼 수 있다. 이 때 컨테이너는 마이크로 서비스(하나의 특정 프로그램)을 사용하기 위한 독립된 컴퓨터로 이해하면 된다. 그림에도 나와 있듯이 컨테이너는 ‘User Space’라는 하나의 Operating system 위에 실행하고자 하는 서비스(Image)로 구성되어 있다는 점도 꼭 기억하도록 하자!

포트 이야기 하다가 왜 컨테이너 구조에 대해서 이야기 하는지 의문이 들 수도 있다고 생각한다. 앞서 포트번호에 대해 이야기 할 때 각각의 서비스 별로 고유한 번호가 부여된다고 언급했다. 그럼 분명 지금 내가 다운 받은 RStudio 서비스 역시 분명 고유한 포트번호가 있을 것이다. 그게 바로 <code>-p 8787:8787</code> 이 명령어에 보이는 8787번 포트인 것이다! 그런데 보면 8787이 ‘:’를 기준으로 앞뒤 두번 쓰여 있는 걸 알 수 있는 데 앞의 8787은 로컬 호스트에 부여된 포트 번호이고, 뒤에 있는 8787은 컨테이너에 부여된 포트 번호이다. **기존 클라이언트 서버의 관점에서 서버 한쪽에만 부여 되었던 포트와는 달리 양쪽 다 포트 번호를 부여하고 있다.**(차이점이다!!) 한가지 더 주목할만한 점은 로컬 호스트에 부여되는 포트 번호는 8787이 아닌 사용자 임의 지정이 가능하다는 점이다. 그럼 또 궁금한 게 생긴다. 언제 이 로컬 호스트의 번호를 임의로 지정할까? 그건 바로 동일한 머신에서 여러 개의 RStudio Server 컨테이너를 실행할 때이다. 이때는 각 컨테이너에 서로 다른 로컬 포트를 지정함으로써 유연성(Piability)을 제공할 수 있다.

하지만 그럼에도 불구하고 로컬 호스트와 컨테이너의 포트 번호를 동일하게 설정하는 이유는 편리성과 더불어 격리성(Isolation) 때문이다. 만약 컨테이너가 여러 개 있을 경우 포트 번호가 같다면 각각의 포트를 찾는 데 쉬워지게 된다. 이 개념의 연장선으로 Isolation에 대해 설명할 수 있는데, 컨테이너는 기본적으로 외부와 완전히 분리된 상태에서 동작한다. 이때 포트 페어를 지정해 로컬과 컨테이너 간 통신을 설정하게 되면 격리된 컨테이너가 외부에서 접근 가능한 상태로 되는 Docker의 진짜 힘을 발휘하게 되는 것이다!



---

다시 웹에서 컨테이너를 실행하는 명령어로 돌아와 이야기 해보도록 하자! 포트 지정까지 완료된 상태에서 뒤를 보면 `-gpus all` 이 있다. 이건 딱 적혀있듯이 실행하고자 하는 로컬의 GPU 자원을 컨테이너에서도 사용할 수 있게 설정하는 것으로 만약 로컬 호스트에 GPU가 탑재 되어 있다면 생략해도 무관하다. 

`v "/home/Arielle/rproject:/home/rstudio/rproject"` 이 부분은 볼륨 마운트(Volume Mount)라는 개념으로 Docker에서 호스트 시스템의 파일이나 디렉토리를 컨테이너 내부와 연결하는 기능을 말한다. 지금 여기서는 로컬 호스트의 `/home/Arielle/rproject` 디렉토리와 컨테이너 내부의 `/home/rstudio/rproject` 디렉토리를 페어링함으로써 로컬에서 작성한 파일을 컨테이너 내부에서 사용할 수도 있고 반대로 컨테이너에서 생성한 파일도 로컬에서 바로 확인할 수 있다. 아래 사진처럼 실제로 로컬에서 `mkdir testforlder` 명령어 실행을 통해 좌측(Container with WEB)의 ‘testfolder’ 생성을 확인할 수 있다. 

<img src="{{ '/assets/p.14/p14.8.png' | relative_url }}" alt="Descriptive Alt Text" />

`-name rstudio-container` 이 옵션은 생성된 컨테이너의 이름을 지정해주는 부분으로 여기서는 `rstudio-container` 라는 이름을 지정하고 있는 것이고, 마지막 `gcr.io/kaggle-gpu-images/rstats:v59` 부분은 Docker 이미지(RStudio)의 경로와 버전을 나타내고 있다.

---

<h2>2. How to work Python package in R?</h2>
컨테이너를 통해 로컬 호스트에 잘 접속 했다면 아래처럼 R프로그램을 만나게 되는데, 사실 나는 R 프로그램을 다뤄 본 적이 없어서 저게 무슨 문법인가 했다. 일단 `reticulate::py_config()`는 R에서 Python 환경을 설정하고 그 환경의 정보를 출력하는 함수이다. 특이하게 R에서는`reticulate` 패키지를 통해 Python을 연동할 수 있는데 실행시켜 보니 “*Would you like to create a default Python environment for the reticulate package? (Yes/no/cancel)”* 문구가 콘솔에 뜨는 걸 확인할 수 있었다. 이 문구는 R과 연동할 Python 환경이 아직 없는 상태로 `reticulate` 패키지가 자동으로 새로운 Python 환경 설치를 물어보는 문구였다. 그래서 일단 YES! 로 Python을 설치해 주었다.

<img src="{{ '/assets/p.14/p14.5.png' | relative_url }}" alt="Descriptive Alt Text" />

참고로 위에서는 RStudio IDE를 이용해 시각적으로 확인할 수 있었다면 이번에는 컨테이너의 터미널 방식으로 RStudio를 확인해 보았다.(어쨋든 GUI, 터미널 둘 다 배워두면 좋으니까요!) `docker ps`로 해당 컨테이너의 이름(rstudio-container)을 먼저 확인해 주었고, 이어서 `docker exec -it rstudio-container R`로 RStudio 경로를 직접 지정해주어 접속했다. 그러면 아래 사진처럼 정상적으로 컨테이너 내부의 터미널에서도 R이 잘 작동하는 것을 확인할 수 있었다.

✅  `docker exec -it rstudio-container R`  여기서 `-it` 는 `-i` (interactive), `-t` (tty)가 합쳐진 명령어로 컨테이너 내부에서 명령어를 실행할 수 있게 해주면서 동시에 터미널에서 입력한 명령어와 출력을 보기 위해 화면을 터미널처럼 만들어주는 기능을 한다! (참고로 해당 터미널에서 exit하고 싶으면 `q()` 로 나오면 된다!)

<img src="{{ '/assets/p.14/p14.6.png' | relative_url }}" alt="Descriptive Alt Text" />

아까 RStudio(WEB)에서 Python을 설치해 주었다. 설치 여부를 물어보길래 얼래벌래 설치를 하기는 했는데 어디에 설치 되었는지 한번 쯤은 확인할 필요가 있을 것 같다. `reticulate::py_config()` 로 터미널에서 확인해보니 `/root/.local/share/r-minicconda/env/r-reticulate/bin/python` 경로에 위치해 있음을 확인했다. 그런데 지금 보면 `r-miniconda` 라는 폴더의 하위 경로에 python이 설치되어 있는 걸로 보이는데, 나는 해당 폴더를 생성한 적이 분명 없다. 

이를 제대로 이해하기 위해서는 Docker 컨테이너 내부에서 RStudio와 Python 환경을 어떻게 연결하고 상호작용하는지 이해할 필요가 있다.

<img src="{{ '/assets/p.14/p14.7.png' | relative_url }}" alt="Descriptive Alt Text" />

<img src="{{ '/assets/p.14/p14.7.1.png' | relative_url }}" alt="Descriptive Alt Text" />

바로 위 그림으로 이해해보도록 하자! 파이썬 패키지를 이용해 Keras, Tensorflow가 R에서 어떻게 작동하는지 플로우를 그린 그림으로 총 5단계로 진행 된다. 

1️⃣ R에서 딥러닝을 수행하려면 R Keras 패키지를 사용해야 한다. 하지만, R 자체에는 Keras나 TensorFlow가 내장되어 있지 않기 때문에 Python 패키지를 불러와 사용해야 한다.

2️⃣ 자 이제 Python 패키지가 필요함을 알았으니 R로 가져와야 하는데 특이하게 R에서는 `reticulate` 라는 패키지가 필요하다. 그래서 `/root/.local/share/r-minicconda/env/r-reticulate/bin/python` 이 경로처럼 `r-reticulate` 가 python의 상위 경로에 있었던 것이다!

3️⃣ 현재 Python 패키지의 경우 reticulate가 사용하는 Python 환경으로 들어오게 된다. 이게 무슨 말이라면 만약 `reticulate`가 miniconda라는 가상 환경을 사용하고 있다면, Python 패키지는 miniconda 환경 안에 설치되어 `miniconda`가 Python 패키지를 저장하고 관리하는 공간이 되는 것이다. 반면에 만약 `reticulate`가 다른 Python 환경을 사용 중이라면,그 환경에 Python 패키지가 설치된다는 뜻이다! 예를 들어 시스템에 미리 설치된 Python이 있다면 그 환경으로 Python 패키지가 설치될 수도 있다. 

아무튼 포인트는 `reticulate`가 사용하는 Python 환경에 따라 Python 패키지가 설치되는 위치가 달라진다는 것이다!

4️⃣ 위의 단계가 정상적으로 진행되면 Python을 위해 keras, tensorflow를 사용할 수 있게 된다. keras는 RStudio에서 알고리즘을 생성할 수 있게 된다.(UI)

5️⃣ 이후 Tensorflow는 Keras의 백엔드로 작동하며  실질적인 연산을 하게 된다.

---

<h2>3. Custom Dockerfile</h2>

앞서 Docker study 3rd에서 Dockerfile에 대해서 알아봤었다. 그때는 붕어빵을 예로 들면서 Dockerfile을 붕어빵 틀을 만드는 레시피 정도로 설명 했었는데, 이번에는 조금 더 소프트웨어 관점에서 생각해보고자 한다. 

---
📂 <strong>Dockerfile?</strong> ([’👉🏻Docker study 3rd'](https://arielle0222.github.io/code%20&%20road/2024/10/11/docker.html))

#**붕어빵 틀**을 만드는 레시피

Dockerfile을 컨테이너에서 실행할 환경을 만드는 레시피로 생각해 봤다(붕어빵🐟🍞 다시 등장). 우리가 어떤 프로그램을 실행하려면 그 프로그램이 돌아가게 할 환경이 필요하다. 예를 들어 프로그램이 Python으로 짜여 있으면 Python을 설치해야 하는 것처럼, Dockerfile은 그런 것들을 자동으로 설정해주는 파일이라고 이해하면 된다.

**A. 베이스 이미지 설정**: 붕어빵을 만들 때 어떤 맛의 반죽을 쓸지 정하는 개념으로 Python이나 Ubuntu 같은 기본 이미지를 설정한다!

**B. 필요한 프로그램 설치**: 붕어빵 반죽에 필요한 재료를 넣는 것과 같다! 프로그램이 실행되기 위해 필요한 **라이브러리나 패키지**를 설치할 수 있다는 뜻으로 예를 들어, 붕어빵 반죽에 초콜릿 칩을 넣듯, 프로그램에 필요한 라이브러리를 추가한다!

**C. 실행 명령어**: 붕어빵이 완성된 후에 어떻게 구울지 정하는 것처럼 컨테이너가 켜졌을 때 어떤 프로그램을 실행할지 설정할 수 있다! 예를 들어 붕어빵을 굽는 온도와 시간을 정할 수 있는 것처럼 프로그램 역시 자동으로 실행될 명령어를 설정할 수 있다!

---

Dockrfile은 우리가 해당 프로그램을 돌아가게 할 수 있는 기본 환경을 만들어주는 파일로 베이스 이미지를 설정하고, 필요한 패키지도 설정하고, 실행 명령어도 직접 설정할 수 있다고 배웠다. 아래 사진은 위에서 우리가 컨테이너 이미지로 사용한 Kaggle R 이미지의 Dockerfile이다. `RUN, ADD, ENV, ARG, LABEL, CMD` 같은 명령어들로 파일이 구성되어 있는 걸 확인할 수 있는데 이들의 기능을 하나씩 정리해보도록 하자!

<img src="{{ '/assets/p.14/p14.3.png' | relative_url }}" alt="Descriptive Alt Text" />

---

<h4>💻 Related Commands</h4>

✅ `ADD` : 로컬 호스트 내 파일이나 폴더를 Docker 이미지로 복사

- 로컬 파일을 컨테이너로 복사하거나 URL에서 파일을 가져올 수도 있고 만약 해당 파일이 압축파일일 경우 자동으로 풀리기도 함
- `ADD kaggle/ /kaggle/`
    - 로컬 호스트의 `kaggle/` 폴더를 컨테이너의 `/kaggle/` 폴더로 복사

✅ `RUN` : 이미지를 빌드할 때 실행할 명령어를 지정

- 주로 프로그램을 설치하거나 스크립트를 실행할 때 사용되고, 이 명령어를 쓸 때마다 새로운 레이어가 만들어짐!
- 🤔 ’새로운 레이어가 만들어진다’는 뜻은 도커의 이미지 관리 측면에서 이해해야 하는데, Docker 이미지는 여러 개의 읽기 전용 레이어로 이루어져 있어 각 레이어는 이전 레이어의 변경 사항을 기억한다. 예를 들어 하나의 이미지를 빌드할 때 **우분투 운영체제 → 패키지 설치 → 파일 복사** 단계를 거치게 되는데 이 한 스텝을 이 레이어(layer)가 관리한다는 의미다! 효율성, 캐싱을 고려했을 때 매우 합리적인 방법임이 분명한데 새로운 RUN 명령을 실행할 때마다 새로운 레이어가 생성되기 때문에, 불필요한 RUN 명령어를 많이 사용하면 이미지가 불필요하게 커질 수 있다. 따라서 **여러 명령을 한 RUN 명령어에 묶어서 실행**하는 것을 추천함!👍
- `RUN R -e "keras::install_keras(tensorflow = \"${TENSORFLOW_VERSION}\", extra_packages = c(\"pandas\"))"`
    - R을 실행해서 `keras`, `tensorflow`, `pandas` 같은 패키지를 설치함

✅ `ENV` : 컨테이너 안에서 사용할 환경 변수를 설정(docker run)

- 이 명령으로 설정된 환경 변수는 Docker 이미지 빌드 후 컨테이너 실행 시에도 유지가 가능함
- `ENV R_HOME=/usr/local/lib/R`
    - `R_HOME`이라는 환경 변수를 `/usr/local/lib/R`로 설정

✅ `ARG` : 이미지 빌드(docker build) 시에 사용할 변수 정의

- `ARG`로 정의된 변수는 빌드 타임(이미지를 만들 때)까지만 사용되고 실행될 때는 사용할 수 없음
- `ARG GIT_COMMIT=unknown
ARG BUILD_DATE_RSTATS=unknown`
    - `GIT_COMMIT`과 `BUILD_DATE_RSTATS`라는 이름을 가지고 있고, 기본값은 'unknown'

✅ `LABEL` : 이미지에 메타데이터(이미지를 설명하는 정보)를 추가함

- 이미지를 만든 날짜나 커밋 정보 등을 넣어서 버전 관리에 도움이 돼요. key-value 형식으로 데이터 저장
- `LABEL git-commit=$GIT_COMMIT
LABEL build-date=$BUILD_DATE_RSTATS`
    - `git-commit`과 `build-date`라는 이름으로 `GIT_COMMIT`과 `BUILD_DATE_RSTATS` 값을 라벨로 지정함

✅ `CMD` : 컨테이너가 시작될 때 기본적으로 실행할 명령을 지정

- `docker run` 명령어로 컨테이너를 실행할 때, 추가 명령을 지정하지 않으면 CMD에서 정한 명령어가 실행됨
- `CMD ["R"]`
    - 이 명령어는 컨테이너가 시작될 때 기본적으로 R 프로그램을 실행

---

이렇게 정리해봤는데, 지금 이 글을 읽고 있는 분이 있다면 이해가 되는지 걱정이다. 사실 명령어 개념 같은 부분은 실제로 내가 직접 실습을 해보는게 가장 빠른 이해 루트라고 생각하다. 그래서 나 역시 위에서 설치한 Kaggle RStudio의 도커파일을 분석해보기로 했다. 

아래 코드는 RStudio 서버 환경을 구축하기 위해 작성된 Dockerfile이다. 간단히 살펴보면 `FROM gcr.io/kaggle-gpu-images/rstats:${rstats_version}` 을 통해 베이스 이미지([gcr.io/kaggle-gpu-images/rstats](http://gcr.io/kaggle-gpu-images/rstats))를 설정하고 있다. 이는 Kaggle GPU 이미지를 기반으로 하여 R과 RStudio 서버를 사용할 수 있게 해준다. 바로 밑의 `RUN` 부분도 중요한데, 뒤의 명령어들을 통해 실질적으로 RStudio 서버를 다운로드 후 설치하고 있다. 관련 명령어들을 구체적으로 설명하지는 않을거지만(검색을 추천합니다!) 아까 위에서 레이어 개념을 설명했는데 연장선으로 `&&` 를 사용해 레이어를 줄이고 있다는 점도 확인 가능하다!

`WORKDIR /home/rstudio` 위에서 다룬 명령어는 아니지만 단어에서 유추할 수 있듯이 구체적으로 작업 디렉토리를 설정해 줄 수도 있다. 

`USER rstudio` 를 통해 해당 컨테이너의 사용자를 ‘rstudio’로 지정해 주었다. 기본적으로 Docker는 `root` 사용자로 실행된다. 다만 보안이나 파일 권한 문제로 인해 특정 작업을 일반 사용자로 지정하는 경우가 많은데 이 때 `USER` 명령어를 이용해 권한을 바꿔줄 수 있다. 

그 외에는 위에서 다뤘던 포트가 눈에 띄는데 `EXPOSE 8787` 지정해주면서 RStudio Server 쪽에 8787번 포트를 열어주었다.

👇 **RStudio server .Dockerfile**

```
  RG rstats_version=v56 

#base image(도커파일의 기본 베이스)는 from으로 불러오기
FROM gcr.io/kaggle-gpu-images/rstats:${rstats_version} 
ARG rstudio_version=2021.09.0-351
RUN apt-get update && \
    apt-get install -y gdebi-core && \
    wget https://download2.rstudio.org/server/focal/amd64/rstudio-server-${rstudio_version}-amd64.deb && \ 
    gdebi -n rstudio-server-${rstudio_version}-amd64.deb && \ 
    apt-get clean && \
    rm rstudio-server-${rstudio_version}-amd64.deb

WORKDIR /home/rstudio
COPY setup.R ./setup.R
RUN chown rstudio:rstudio ./setup.R
RUN chmod +x ./setup.R
USER rstudio
RUN Rscript ./setup.R && \
    rm ./setup.R
USER root


EXPOSE 8787
# LABEL revised_by="Daniel Youk" \
#       revised_date="2023-12-24"
ENTRYPOINT [ "/bin/bash"]
CMD ["-c", "rstudio-server start && tail -f /dev/null"]

```

그리고 한가지 중요한 점은 `CMD ["-c", "rstudio-server start && tail -f /dev/null"]` 이 명령어다. 위에서 `CMD` 를 ‘컨테이너가 시작될 때 기본적으로 실행할 명령을 지정’한다고 설명했다. 이 부분은 내 경험 상 예시 하나의 비교를 통해 바로 이해가 가능했다. 

아래 사진은 위에서 다룬 Kaggle R 이미지의 Dockerfile의 가장 마지막 줄의 캡쳐 부분이다. 보면 `CMD [”R”]` 이라고 적혀있는데, `CMD` 로 컨테이너 시작 명령어를 지정할 수 있기 때문에 해당 컨테이너를 실행하기 위한 기본 명령어(docker exec)를 응용해  `docker exec -it rstudio-container R` 이렇게 사용할 수 있다. 이 명령어로 바로  rstudio-container의 R 프로그램에 접근할 수 있는 것이다. 

<img src="{{ '/assets/p.14/p14.3.1.png' | relative_url }}" alt="Descriptive Alt Text" />

<img src="{{ '/assets/p.14/p14.6.png' | relative_url }}" alt="Descriptive Alt Text" />

그런데 RStudio Server를 구축하는 도커파일에도 `CMD` 명령어가 있다. 그런데 분명 생김새가 다른 걸로 보아 차이점이 있는 것이 확실하다.(뭐지..) 결론부터 말하자면 `CMD ["-c", "rstudio-server start && tail -f /dev/null"]` 명령어는 RStudio 서버를 시작하고 컨테이너가 종료되지 않게 유지하는 기능을 한다. `/dev/null`은 리눅스 시스템에서 특별한 파일로 입력된 데이터를 모두 버리는 역할을 하는데 `tail -f` 명령어로 `/dev/null` 파일을 계속 찾으려고 한다. 하지만 해당 파일은 앞서 말했듯이 무언가 입력되면 데이터를 모두 버리는 역할을 하기 때문에 무한루프에 빠지게 되고 컨테이너가 종료되지 않게 유지하는 기능을 할 수 있는 것이다!

<h4>3.1 Difference Between Docker CMD and ENTRYPOINT: When and How to Use Them?</h4>

Dockerfile을 작성할 때 CMD와 ENTRYPOINT 두 명령어가 계속 나왔다. **둘다 컨테이너가 시작될 때 실행될 명령을 지정**하는 데 사용되는 건 똑같지만 그 역할과 동작 방식에 차이가 있는 것 같다. 이 부분도 다시는 헷갈리기 싫으니 여기서 정리해 보려고 한다!

<h4>🚪 CMD</h4>

계속 언급되었던 CMD는 컨테이너가 실행될 때마다 수행되지만 덮어쓰기가 가능하다. 만약 사용자가 `docker run` 명령어를 실행하면서 다른 명령을 입력하면 CMD에서 지정한 명령은 실행되지 않고 새로 입력한 명령이 대신 실행이 가능하다. 예시를 통해 이해해보도록 하자!

우리는 `CMD ["R"]` 이 코드를 이용해 컨테이너가 시작되면 R 콘솔이 기본으로 실행됨을 위에서 확인했다. 그런데 만약 사용자가 컨테이너를 실행 하면서 다른 명령을 입력한다면 CMD에서 지정한 `R`은 무시되고 새로운 명령이 실행된다. 이게 무슨 말인가 하면 `docker run <image> /bin/bash` 로 명령어를 실행하면 `R` 대신 `/bin/bash`가 실행 된다는 말이다.

<h4>🚪 Entry Point</h4>

ENTRYPOINT는 항상 실행될 명령을 지정하는 데 사용된다. CMD와 달리 `docker run`에서 다른 명령을 입력해도 ENTRYPOINT에서 지정한 명령은 덮어쓰이지 않으며 그대로 실행되는 게 둘의 가장 큰 특징이다. 이것도 예시를 통해 이해해보록 하자!

`ENTRYPOINT ["/bin/bash", "-c"]` 이 코드는 컨테이너가 실행될 때 항상 <code>/bin/bash -c</code>를 실행하도록 한다. 그런데 만약 사용자가 `docker run`을 이용해 `docker run <image> "echo Hello"`를 실행하면 그 명령은 <code>/bin/bash -c</code> 의 인자로 전달되어 <code>/bin/bash -c "echo Hello"</code>로 실행된다!


👇 **summary**

<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CMD vs ENTRYPOINT</title>
    <style>
        table {
            width: 100%;
            border-collapse: collapse;
        }
        th, td {
            border: 1px solid #dddddd;
            text-align: left;
            padding: 8px;
        }
        th {
            background-color: #99CCFF;
        }
        td {
            vertical-align: top;
        }
    </style>
</head>
<body>

<table>
    <thead>
        <tr>
            <th>항목</th>
            <th>CMD</th>
            <th>ENTRYPOINT</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>목적</td>
            <td>기본 명령을 설정 (덮어쓰기 가능)</td>
            <td>필수 명령을 설정 (항상 실행됨)</td>
        </tr>
        <tr>
            <td>덮어쓰기</td>
            <td>`docker run` 명령어로 덮어씌움</td>
            <td>덮어쓰지 않고, 인자를 전달 가능</td>
        </tr>
        <tr>
            <td>유연성</td>
            <td>다른 명령으로 대체할 수 있음</td>
            <td>인자를 통해 명령 추가 가능</td>
        </tr>
        <tr>
            <td>예시</td>
            <td>`CMD ["R"]`</td>
            <td>`ENTRYPOINT ["/bin/bash", "-c"]`</td>
        </tr>
    </tbody>
</table>

</body>
</html>

결론적으로 두 명령어 모두 컨테이너가 시작될 때 실행될 명령을 지정하지만 CMD는 기본 실행 명령을, ENTRYPOINT는 항상 실행되어야 하는 필수 명령을 설정하는 데 사용된다는 점을 꼭기억하길 바란다! 아래 코드는 실제 프로젝트에서 많이 사용하는 조합이니 참고하면 좋을 듯 하다!

```
ENTRYPOINT ["/bin/bash", "-c"]
CMD ["rstudio-server start && tail -f /dev/null"]
```

---

<h2>4. Docker Pipeline</h2>
이번 포스팅을 마무리 하기 전에 지금까지의 학습 과정을 시각적으로 정리해 보려고 한다. 지금까지의 포스팅은 Dockerfile을 통해 이미지 생성하고 그 이미지를 통해 컨테이너 실행하는 부분까지 진행되었다. (Dockerfile → 이미지 생성 → Registry 저장 → 이미지 가져오기 → 컨테이너 실행) 

지금이야 이미지를 만들고 로컬에서 실행하는 데 큰 문제가 없었다. 하지만 컨테이너에서 사용하는 이미지들이 많아진다면 로컬이라는 한정된 공간에서 효율성이 떨어지게 된다. 그래서 보통은 Docker Registry라는 곳에 이미지를 저장(push)하고 필요할 때마다 당겨와(pull) 로컬 혹은 가상머신에서 사용하는 게 일반적이다. 다음 포스팅 부터는 이 이야기를 중심으로 진행되니 기대해 주길 바란다! 😎

<img src="{{ '/assets/p.14/p14.14.png' | relative_url }}" alt="Descriptive Alt Text" />

---

*이번 주차는 지금까지 도커를 공부하며 비유적으로 이해했던 부분들에 대해 조금 더 소프트웨어 측면에서 이론을 다루었다. 그러다보니 뭐랄까.. 분명 내가 알고 있던 내용이였던 것 같은데 또다시 새로운 내용이 되어버린 것 같았다. 특히 Dockerfile의 ENV, ARG 명령어에 대해서는 이미지를 빌드할 때, 컨테이너를 실행할 때로 구분되는데, 구체적으로 도커파일을 직접 생성해보면서 개념을 다질 필요가 있다고 느꼈다.* 

*아무튼 이번주차를 기점으로 도커 포스팅 시리즈도 반환점을 돌았다. 여전히 많이 부족한 글이지만 분명 글로 남기고 정리하는 건 이해의 농도가 다를 거라고 생각한다. 이번주는 유난히 뭘 해도 집중이 안되는 날이었는데 일단 버텨보는 걸로 하자!*👊

<img src="{{ '/assets/p.14/outro.gif' | relative_url }}" alt="Descriptive Alt Text" />

---
### Reference

[Kaggle_R_Dockerfile](References
https://github.com/Kaggle/docker-rstats/blob/main/Dockerfile)

[Please allow me to introduce myself: Torch for R](https://blogs.rstudio.com/ai/posts/2020-09-29-introducing-torch-for-r/)